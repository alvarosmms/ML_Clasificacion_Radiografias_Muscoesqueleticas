{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SISTEMA Y UTILIDADES\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# VISUALIZACIÓN Y EVALUACIÓN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# TORCH\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# SOLUCIÓN PARA ARCHIVOS CORRUPTOS\n",
    "from PIL import UnidentifiedImageError\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Clase personalizada para evitar errores al cargar imágenes corruptas\n",
    "class SafeImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return super().__getitem__(index)\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            new_index = (index + 1) % len(self)\n",
    "            return self.__getitem__(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: ['XR_ELBOW', 'XR_FINGER', 'XR_FOREARM', 'XR_HAND', 'XR_HUMERUS', 'XR_SHOULDER', 'XR_WRIST']\n"
     ]
    }
   ],
   "source": [
    "# Ruta al dataset\n",
    "DATA_DIR = Path(\"/Users/alvarosanchez/Downloads/MURA-v1.1\")  # Cambia esto a \"data/MURA-v1.1\" para usar el dataset completo\n",
    "\n",
    "# Transformaciones para entrenamiento con augmentación\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Transformaciones para validación: sin augmentación\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Carga segura de datasets\n",
    "train_dataset = SafeImageFolder(DATA_DIR / \"train\", transform=transform_train)\n",
    "valid_dataset = SafeImageFolder(DATA_DIR / \"valid\", transform=transform_val)\n",
    "\n",
    "# DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Verificamos las clases\n",
    "print(\"Clases:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomHorizontalFlip, Rotation y ColorJitter simulan variaciones reales que podrías encontrar en radiografías (posiciones del brazo, luz, etc.).\n",
    "\n",
    "El uso de Normalize es importante porque los modelos preentrenados en ImageNet esperan imágenes normalizadas con esas medias y desviaciones estándar.\n",
    "\n",
    "SafeImageFolder es clave para evitar errores con imágenes corruptas (frecuentes en MURA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos modelo preentrenado con pesos de ImageNet\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# Congelamos TODAS las capas al principio\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelamos la última capa convolucional: layer4\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# También descongelamos la capa totalmente conectada (fc)\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Ajustamos la capa de salida para clasificación binaria\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 2)  # 2 clases: 'negative', 'positive'\n",
    "\n",
    "# Enviamos el modelo al dispositivo adecuado (GPU o Apple M3)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo se basa en ResNet18, una red convolucional profunda entrenada sobre ImageNet. \n",
    "\n",
    "En lugar de entrenar todo desde cero, aprovechamos su conocimiento general de imágenes (bordes, formas, texturas), \n",
    "\n",
    "pero le permitimos reajustar su parte final (layer4) para que aprenda las particularidades de las radiografías musculoesqueléticas. \n",
    "\n",
    "Esto se conoce como fine-tuning parcial.\n",
    "\n",
    "La última capa (fc) también se entrena desde cero para adaptarse a nuestra tarea de clasificación binaria: positive o negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases: Counter({6: 9752, 5: 8379, 3: 5543, 1: 5106, 0: 4931, 2: 1825, 4: 1272})\n"
     ]
    }
   ],
   "source": [
    "# Conteo de clases reales (binary: 0 = negative, 1 = positive)\n",
    "labels = [label for _, label in train_dataset.samples]\n",
    "class_counts = Counter(labels)\n",
    "print(\"Distribución de clases:\", class_counts)\n",
    "\n",
    "# Cálculo correcto para 2 clases\n",
    "total = sum(class_counts.values())\n",
    "class_weights = [total / class_counts[i] for i in range(2)]\n",
    "weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "# Función de pérdida con pesos binarios\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar que el modelo favorezca la clase mayoritaria, calculamos pesos de clase basados en su frecuencia inversa. \n",
    "\n",
    "De este modo, cometer errores en la clase menos representada penaliza más durante el entrenamiento, \n",
    "\n",
    "ayudando a equilibrar la precisión y el recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.0019 | Val Loss: 0.0018 | Acc: 0.2893 | F1: 0.1282\n",
      "Mejor modelo guardado.\n",
      "Epoch 2 | Train Loss: 0.0011 | Val Loss: 0.0038 | Acc: 0.2890 | F1: 0.1282\n",
      "Epoch 3 | Train Loss: 0.0007 | Val Loss: 0.0006 | Acc: 0.2893 | F1: 0.1284\n",
      "Mejor modelo guardado.\n",
      "Epoch 4 | Train Loss: 0.0007 | Val Loss: 0.0009 | Acc: 0.2893 | F1: 0.1286\n",
      "Epoch 5 | Train Loss: 0.0009 | Val Loss: 0.0006 | Acc: 0.2896 | F1: 0.1283\n",
      "Epoch 6 | Train Loss: 0.0005 | Val Loss: 0.0013 | Acc: 0.2890 | F1: 0.1281\n",
      "Epoch 7 | Train Loss: 0.0008 | Val Loss: 0.0003 | Acc: 0.2896 | F1: 0.1289\n",
      "Mejor modelo guardado.\n",
      "Epoch 8 | Train Loss: 0.0005 | Val Loss: 0.0005 | Acc: 0.2893 | F1: 0.1284\n",
      "Epoch 9 | Train Loss: 0.0003 | Val Loss: 0.0012 | Acc: 0.2893 | F1: 0.1286\n",
      "Epoch 10 | Train Loss: 0.0001 | Val Loss: 0.0006 | Acc: 0.2893 | F1: 0.1283\n",
      "Epoch 11 | Train Loss: 0.0003 | Val Loss: 0.0007 | Acc: 0.2893 | F1: 0.1282\n",
      "Epoch 12 | Train Loss: 0.0002 | Val Loss: 0.0017 | Acc: 0.2893 | F1: 0.1287\n",
      "Early stopping activado.\n"
     ]
    }
   ],
   "source": [
    "# Hiperparámetros\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "PATIENCE = 5  # early stopping\n",
    "\n",
    "# Optimizador y scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,\n",
    "                                                 patience=2, verbose=True)\n",
    "\n",
    "# Entrenamiento con early stopping\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validación\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Métricas\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "    # Guardado del mejor modelo\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        os.makedirs(\"src/models\", exist_ok=True)\n",
    "        torch.save(model.state_dict(), \"/Users/alvarosanchez/ONLINE_DS_THEBRIDGE_ALVAROSMMS-1/ML_Clasificacion_Radiografias_Muscoesqueleticas/src/models/resnet18_finetuned.pt\")\n",
    "        print(\"Mejor modelo guardado.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"Early stopping activado.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
