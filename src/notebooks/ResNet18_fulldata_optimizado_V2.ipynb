{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MURABinaryDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for root, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".png\") and \"._\" not in file:\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    label = 1 if \"positive\" in root.lower() else 0\n",
    "                    self.samples.append((full_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train imgs: 36808 | Valid imgs: 3197\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/Users/alvarosanchez/Downloads/MURA-v1.1\"\n",
    "\n",
    "train_dataset = MURABinaryDataset(os.path.join(DATA_DIR, \"train\"), transform=transform_train)\n",
    "valid_dataset = MURABinaryDataset(os.path.join(DATA_DIR, \"valid\"), transform=transform_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "\n",
    "print(f\"Train imgs: {len(train_dataset)} | Valid imgs: {len(valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model = model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de clase: tensor([1.6780, 2.4748], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "# Configuración\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 3\n",
    "\n",
    "# Calcular pesos de clase para pérdida ponderada\n",
    "labels = [label for _, label in train_dataset]\n",
    "class_counts = Counter(labels)\n",
    "total = sum(class_counts.values())\n",
    "class_weights = [total / class_counts[i] for i in range(len(class_counts))]\n",
    "class_weights = torch.FloatTensor(class_weights).to(DEVICE)\n",
    "print(f\"Pesos de clase: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.6603 | Val Loss: 0.6595 | Acc: 0.6331 | F1: 0.5857\n",
      "Mejor modelo guardado.\n",
      "Epoch 2 | Train Loss: 0.6293 | Val Loss: 0.6919 | Acc: 0.6315 | F1: 0.4987\n",
      "Epoch 3 | Train Loss: 0.6177 | Val Loss: 0.6493 | Acc: 0.6537 | F1: 0.5831\n",
      "Mejor modelo guardado.\n",
      "Epoch 4 | Train Loss: 0.6112 | Val Loss: 0.6498 | Acc: 0.6591 | F1: 0.5915\n",
      "Epoch 5 | Train Loss: 0.6075 | Val Loss: 0.6540 | Acc: 0.6550 | F1: 0.5759\n",
      "Epoch 6 | Train Loss: 0.6042 | Val Loss: 0.6371 | Acc: 0.6616 | F1: 0.6054\n",
      "Mejor modelo guardado.\n",
      "Epoch 7 | Train Loss: 0.6034 | Val Loss: 0.6431 | Acc: 0.6597 | F1: 0.5885\n",
      "Epoch 8 | Train Loss: 0.6001 | Val Loss: 0.6490 | Acc: 0.6584 | F1: 0.5758\n",
      "Epoch 9 | Train Loss: 0.5987 | Val Loss: 0.6318 | Acc: 0.6669 | F1: 0.6100\n",
      "Mejor modelo guardado.\n",
      "Epoch 10 | Train Loss: 0.6001 | Val Loss: 0.6296 | Acc: 0.6678 | F1: 0.6161\n",
      "Mejor modelo guardado.\n",
      "Epoch 11 | Train Loss: 0.6010 | Val Loss: 0.6341 | Acc: 0.6631 | F1: 0.5989\n",
      "Epoch 12 | Train Loss: 0.5970 | Val Loss: 0.6488 | Acc: 0.6575 | F1: 0.5701\n",
      "Epoch 13 | Train Loss: 0.5966 | Val Loss: 0.6324 | Acc: 0.6731 | F1: 0.6122\n",
      "Early stopping activado.\n"
     ]
    }
   ],
   "source": [
    "# Definimos el criterio con pesos para clases desbalanceadas\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Solo entrenamos la última capa (fc) ya que el resto está congelada\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Reducir el LR si la validación no mejora\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "# Variables para control de entrenamiento\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # VALIDACIÓN\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "    # Guardar el mejor modelo\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"/Users/alvarosanchez/ONLINE_DS_THEBRIDGE_ALVAROSMMS-1/ML_Clasificacion_Radiografias_Muscoesqueleticas/src/models/resnet18_optimizedV2.pt\")\n",
    "        print(\"Mejor modelo guardado.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"Early stopping activado.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
